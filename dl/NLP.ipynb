{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "Working with written language is called natural language processing (NLP) and is a much broader field than deep learning. We'll focus just on deep learning in NLP and specifically it's application to molecules and materials. NLP in chemistry would at first appear to be a rich area, especially with the large amount of historic chemistry data existing only in plain text. However, the most work in this area has been on representations of molecules *as text* via the SMILES {cite} or SELFIES {cite} encoding. To a large extent, this is another way of \"featurizing\" molecules without resorting to descriptors. The biggest advantage of working with molecules as text relative to graph neural networks (GNNs) is that it is easier to generate novel molecule. You'll thus see generative/unsupervised learning of chemical space more often done with NLP, whereas GNNs are typically better for supervised learning tasks and can incorporate spatial data. NLP is also used beyond encoding molecules. NLP can be used to understand textual descriptions of materials and molecules, which is essential for *materials* that are defined with more than just the moluecular structure.\n",
    "\n",
    "```{margin}\n",
    "I'm going to completely skip recurrent neural networks (RNNs). Although they have been historically important, I think they've been displaced by transformers and so we'll save some space. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Molecules into Text\n",
    "\n",
    "Simplified molecular-input line-entry system (SMILES) is a de facto standard for converting molecules into a string. SMILES enables molecular structures to be correctly saved in spreadsheets, text files, and input to models that work on sequences like text. Here's an example SMILES string: CC(NC)CC1=CC=C(OCO2)C2=C1. SMILES was crucial to the field of cheminformatics and is widely used. Some of the first deep learning work was with SMILES strings because of the ability to apply NLP models to SMILES strings. \n",
    "\n",
    "Let us imagine SMILES as a function whose domain is molecular graphs (or some equivalent complete description of a molecule) and image is a string. A problem with the hypothetical SMILES function is that\n",
    "\n",
    "\n",
    "### SELFIES\n",
    "\n",
    "## Transformers \n",
    "\n",
    "## Generative Models\n",
    "\n",
    "### VAE\n",
    "\n",
    "### Latent Space\n",
    "\n",
    "## Materials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
