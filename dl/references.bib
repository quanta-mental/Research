@article{finn2017model,
  title   = {Model-agnostic meta-learning for fast adaptation of deep networks},
  author  = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  journal = {arXiv preprint arXiv:1703.03400},
  year    = {2017}
}

@article{45826,
  title   = {Neural Architecture Search with Reinforcement Learning},
  author  = {Barret Zoph and Quoc V. Le},
  journal = {arXiv preprint arXiv:1611.01578},
  year    = {2017},
  url     = {https://arxiv.org/abs/1611.01578}
}


@article{LeNet,
  author  = {Y. {Lecun} and L. {Bottou} and Y. {Bengio} and P. {Haffner}},
  journal = {Proceedings of the IEEE},
  title   = {Gradient-based learning applied to document recognition},
  year    = {1998},
  volume  = {86},
  number  = {11},
  pages   = {2278-2324}
}


@article{hyperband,
  author  = {Lisha Li and Kevin Jamieson and Giulia DeSalvo and Afshin Rostamizadeh and Ameet Talwalkar},
  title   = {Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2018},
  volume  = {18},
  number  = {185},
  pages   = {1-52},
  url     = {http://jmlr.org/papers/v18/16-558.html}
}

@inproceedings{zhao2020exploring,
  title     = {Exploring self-attention for image recognition},
  author    = {Zhao, Hengshuang and Jia, Jiaya and Koltun, Vladlen},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {10076--10085},
  year      = {2020}
}



@inproceedings{glorot2010understanding,
  title     = {Understanding the difficulty of training deep feedforward neural networks},
  author    = {Glorot, Xavier and Bengio, Yoshua},
  booktitle = {Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages     = {249--256},
  year      = {2010}
}




@article{noconv,
  author  = {Cireşan, Dan Claudiu and Meier, Ueli and Gambardella, Luca Maria and Schmidhuber, Jürgen},
  title   = {Deep, Big, Simple Neural Nets for Handwritten Digit Recognition},
  journal = {Neural Computation},
  volume  = {22},
  number  = {12},
  pages   = {3207-3220},
  year    = {2010},
  doi     = {10.1162/NECO\_a\_00052}
}



@article{solubility,
  title     = {Bioinformatics approaches for improved recombinant protein production in Escherichia coli: protein solubility prediction},
  author    = {Chang, Catherine Ching Han and Song, Jiangning and Tey, Beng Ti and Ramanan, Ramakrishnan Nagasundara},
  journal   = {Briefings in bioinformatics},
  volume    = {15},
  number    = {6},
  pages     = {953--962},
  year      = {2014},
  publisher = {Oxford University Press}
}

@article{deepsol,
  author   = {Khurana, Sameer and Rawi, Reda and Kunji, Khalid and Chuang, Gwo-Yu and Bensmail, Halima and Mall, Raghvendra},
  title    = {{DeepSol: a deep learning framework for sequence-based protein solubility prediction}},
  journal  = {Bioinformatics},
  volume   = {34},
  number   = {15},
  pages    = {2605-2613},
  year     = {2018},
  month    = {03},
  abstract = {{Protein solubility plays a vital role in pharmaceutical research and production yield. For a given protein, the extent of its solubility can represent the quality of its function, and is ultimately defined by its sequence. Thus, it is imperative to develop novel, highly accurate in silico sequence-based protein solubility predictors. In this work we propose, DeepSol, a novel Deep Learning-based protein solubility predictor. The backbone of our framework is a convolutional neural network that exploits k-mer structure and additional sequence and structural features extracted from the protein sequence.DeepSol outperformed all known sequence-based state-of-the-art solubility prediction methods and attained an accuracy of 0.77 and Matthew’s correlation coefficient of 0.55. The superior prediction accuracy of DeepSol allows to screen for sequences with enhanced production capacity and can more reliably predict solubility of novel proteins.DeepSol’s best performing models and results are publicly deposited at https://doi.org/10.5281/zenodo.1162886 (Khurana and Mall, 2018).Supplementary data are available at Bioinformatics online.}},
  issn     = {1367-4803},
  doi      = {10.1093/bioinformatics/bty166},
  url      = {https://doi.org/10.1093/bioinformatics/bty166},
  eprint   = {https://academic.oup.com/bioinformatics/article-pdf/34/15/2605/25230875/bty166.pdf}
}



@article{neal2018modern,
  title   = {A modern take on the bias-variance tradeoff in neural networks},
  author  = {Neal, Brady and Mittal, Sarthak and Baratin, Aristide and Tantia, Vinayak and Scicluna, Matthew and Lacoste-Julien, Simon and Mitliagkas, Ioannis},
  journal = {arXiv preprint arXiv:1810.08591},
  year    = {2018}
}

@inproceedings{gal2016dropout,
  title     = {Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author    = {Gal, Yarin and Ghahramani, Zoubin},
  booktitle = {international conference on machine learning},
  pages     = {1050--1059},
  year      = {2016}
}


@article{kipf2016semi,
  title   = {Semi-supervised classification with graph convolutional networks},
  author  = {Kipf, Thomas N and Welling, Max},
  journal = {arXiv preprint arXiv:1609.02907},
  year    = {2016}
}

@article{battaglia2018relational,
  title   = {Relational inductive biases, deep learning, and graph networks},
  author  = {Battaglia, Peter W and Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and others},
  journal = {arXiv preprint arXiv:1806.01261},
  year    = {2018}
}

@article{li2015gated,
  title   = {Gated graph sequence neural networks},
  author  = {Li, Yujia and Tarlow, Daniel and Brockschmidt, Marc and Zemel, Richard},
  journal = {arXiv preprint arXiv:1511.05493},
  year    = {2015}
}

@article{chung2014empirical,
  title   = {Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author  = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal = {arXiv preprint arXiv:1412.3555},
  year    = {2014}
}

@article{gilmer2017neural,
  title   = {Neural message passing for quantum chemistry},
  author  = {Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E},
  journal = {arXiv preprint arXiv:1704.01212},
  year    = {2017}
}

@inproceedings{vaswani2017attention,
  title     = {Attention is all you need},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle = {Advances in neural information processing systems},
  pages     = {5998--6008},
  year      = {2017}
}

@article{luong2015effective,
  title   = {Effective approaches to attention-based neural machine translation},
  author  = {Luong, Minh-Thang and Pham, Hieu and Manning, Christopher D},
  journal = {arXiv preprint arXiv:1508.04025},
  year    = {2015}
}
@article{zhang2018gaan,
  title   = {Gaan: Gated attention networks for learning on large and spatiotemporal graphs},
  author  = {Zhang, Jiani and Shi, Xingjian and Xie, Junyuan and Ma, Hao and King, Irwin and Yeung, Dit-Yan},
  journal = {arXiv preprint arXiv:1803.07294},
  year    = {2018}
}

@article{treisman1980feature,
  title     = {A feature-integration theory of attention},
  author    = {Treisman, Anne M and Gelade, Garry},
  journal   = {Cognitive psychology},
  volume    = {12},
  number    = {1},
  pages     = {97--136},
  year      = {1980},
  publisher = {Elsevier}
}

@article{BALUJA1997329,
  title    = {Expectation-based selective attention for visual monitoring and control of a robot vehicle},
  journal  = {Robotics and Autonomous Systems},
  volume   = {22},
  number   = {3},
  pages    = {329 - 344},
  year     = {1997},
  note     = {Robot Learning: The New Wave},
  issn     = {0921-8890},
  doi      = {https://doi.org/10.1016/S0921-8890(97)00046-8},
  url      = {http://www.sciencedirect.com/science/article/pii/S0921889097000468},
  author   = {Shumeet Baluja and Dean A. Pomerleau},
  keywords = {Expectation-based selective attention, Autonomous navigation, Temporal coherence, Saliency map, Artificial neural networks},
  abstract = {Reliable vision-based control of an autonomous vehicle requires the ability to focus attention on the important features in an input scene. Previous work with an autonomous lane following system, ALVINN (Pomerleau, 1993), has yielded good results in uncluttered conditions. This paper presents an artificial neural network based learning approach for handling difficult scenes which will confuse the ALVINN system. This work presents a mechanism for achieving task-specific focus of attention by exploiting temporal coherence. A saliency map, which is based upon a computed expectation of the contents of the inputs in the next time step, indicates which regions of the input retina are important for performing the task. The saliency map can be used to accentuate the features which are important for the task, and de-emphasize those which are not.}
}

@article{thomas2018tensor,
  title   = {Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds},
  author  = {Thomas, Nathaniel and Smidt, Tess and Kearnes, Steven and Yang, Lusann and Li, Li and Kohlhoff, Kai and Riley, Patrick},
  journal = {arXiv preprint arXiv:1802.08219},
  year    = {2018}
}

@inproceedings{weiler20183d,
  title     = {3d steerable cnns: Learning rotationally equivariant features in volumetric data},
  author    = {Weiler, Maurice and Geiger, Mario and Welling, Max and Boomsma, Wouter and Cohen, Taco S},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {10381--10392},
  year      = {2018}
}

@article{rupp2012fast,
  title     = {Fast and accurate modeling of molecular atomization energies with machine learning},
  author    = {Rupp, Matthias and Tkatchenko, Alexandre and M{\"u}ller, Klaus-Robert and Von Lilienfeld, O Anatole},
  journal   = {Physical review letters},
  volume    = {108},
  number    = {5},
  pages     = {058301},
  year      = {2012},
  publisher = {APS}
}

@article{Bart,
  title     = {On representing chemical environments},
  author    = {Bart\'ok, Albert P. and Kondor, Risi and Cs\'anyi, G\'abor},
  journal   = {Phys. Rev. B},
  volume    = {87},
  issue     = {18},
  pages     = {184115},
  numpages  = {16},
  year      = {2013},
  month     = {May},
  publisher = {American Physical Society},
  doi       = {10.1103/PhysRevB.87.184115},
  url       = {https://link.aps.org/doi/10.1103/PhysRevB.87.184115}
}


@article{behler2011atom,
  title     = {Atom-centered symmetry functions for constructing high-dimensional neural network potentials},
  author    = {Behler, J{\"o}rg},
  journal   = {The Journal of chemical physics},
  volume    = {134},
  number    = {7},
  pages     = {074106},
  year      = {2011},
  publisher = {American Institute of Physics}
}

@inproceedings{ravanbakhsh2017equivariance,
  title     = {Equivariance Through Parameter-Sharing},
  author    = {Ravanbakhsh, Siamak and Schneider, Jeff and P{\'o}czos, Barnab{\'a}s},
  booktitle = {International Conference on Machine Learning},
  pages     = {2892--2901},
  year      = {2017}
}

@article{mesquita2020rethinking,
  title   = {Rethinking pooling in graph neural networks},
  author  = {Mesquita, Diego and Souza, Amauri and Kaski, Samuel},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {33},
  year    = {2020}
}

@article{luzhnica2019graph,
  title   = {On graph classification networks, datasets and baselines},
  author  = {Luzhnica, Enxhell and Day, Ben and Li{\`o}, Pietro},
  journal = {arXiv preprint arXiv:1905.04682},
  year    = {2019}
}

@inproceedings{xu2018powerful,
  title     = {How Powerful are Graph Neural Networks?},
  author    = {Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  booktitle = {International Conference on Learning Representations},
  year      = {2018}
}

@inproceedings{hamilton2017inductive,
  title     = {Inductive representation learning on large graphs},
  author    = {Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
  booktitle = {Advances in neural information processing systems},
  pages     = {1024--1034},
  year      = {2017}
}


@article{shchur2018pitfalls,
  title   = {Pitfalls of graph neural network evaluation},
  author  = {Shchur, Oleksandr and Mumme, Maximilian and Bojchevski, Aleksandar and G{\"u}nnemann, Stephan},
  journal = {arXiv preprint arXiv:1811.05868},
  year    = {2018}
}

@inproceedings{errica2019fair,
  title     = {A Fair Comparison of Graph Neural Networks for Graph Classification},
  author    = {Errica, Federico and Podda, Marco and Bacciu, Davide and Micheli, Alessio},
  booktitle = {International Conference on Learning Representations},
  year      = {2019}
}
@article{dwivedi2020benchmarking,
  title   = {Benchmarking graph neural networks},
  author  = {Dwivedi, Vijay Prakash and Joshi, Chaitanya K and Laurent, Thomas and Bengio, Yoshua and Bresson, Xavier},
  journal = {arXiv preprint arXiv:2003.00982},
  year    = {2020}
}

@article{bronstein2017geometric,
  title     = {Geometric deep learning: going beyond euclidean data},
  author    = {Bronstein, Michael M and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre},
  journal   = {IEEE Signal Processing Magazine},
  volume    = {34},
  number    = {4},
  pages     = {18--42},
  year      = {2017},
  publisher = {IEEE}
}

@article{wu2020comprehensive,
  title     = {A comprehensive survey on graph neural networks},
  author    = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  year      = {2020},
  publisher = {IEEE}
}

@article{kobyzev2020normalizing,
  title     = {Normalizing flows: An introduction and review of current methods},
  author    = {Kobyzev, Ivan and Prince, Simon and Brubaker, Marcus},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2020},
  publisher = {IEEE}
}

@inproceedings{papamakarios2017masked,
  title     = {Masked autoregressive flow for density estimation},
  author    = {Papamakarios, George and Pavlakou, Theo and Murray, Iain},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {2338--2347},
  year      = {2017}
}

@inproceedings{kingma2016improved,
  title     = {Improved variational inference with inverse autoregressive flow},
  author    = {Kingma, Durk P and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
  booktitle = {Advances in neural information processing systems},
  pages     = {4743--4751},
  year      = {2016}
}

@article{kim2018flowavenet,
  title   = {FloWaveNet: A generative flow for raw audio},
  author  = {Kim, Sungwon and Lee, Sang-gil and Song, Jongyoon and Kim, Jaehyeon and Yoon, Sungroh},
  journal = {arXiv preprint arXiv:1811.02155},
  year    = {2018}
}

@article{dinh2016density,
  title   = {Density estimation using real nvp},
  author  = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  journal = {arXiv preprint arXiv:1605.08803},
  year    = {2016}
}

@article{das2019dimensionality,
  title   = {Dimensionality reduction flows},
  author  = {Das, Hari Prasanna and Abbeel, Pieter and Spanos, Costas J},
  journal = {arXiv preprint arXiv:1908.01686},
  year    = {2019}
}

@article{foote2000relation,
  title     = {A relation between the principal axes of inertia and ligand binding},
  author    = {Foote, Jefferson and Raman, Anandi},
  journal   = {Proceedings of the National Academy of Sciences},
  volume    = {97},
  number    = {3},
  pages     = {978--983},
  year      = {2000},
  publisher = {National Acad Sciences}
}

@article{esteves2020theoretical,
  title   = {Theoretical Aspects of Group Equivariant Neural Networks},
  author  = {Esteves, Carlos},
  journal = {arXiv preprint arXiv:2004.05154},
  year    = {2020}
}

@article{krenn2020self,
  title     = {Self-Referencing Embedded Strings (SELFIES): A 100\% robust molecular string representation},
  author    = {Krenn, Mario and H{\"a}se, Florian and Nigam, AkshatKumar and Friederich, Pascal and Aspuru-Guzik, Alan},
  journal   = {Machine Learning: Science and Technology},
  volume    = {1},
  number    = {4},
  pages     = {045024},
  year      = {2020},
  publisher = {IOP Publishing}
}

@inproceedings{mathieu2019disentangling,
  title     = {Disentangling disentanglement in variational autoencoders},
  author    = {Mathieu, Emile and Rainforth, Tom and Siddharth, N and Teh, Yee Whye},
  booktitle = {International Conference on Machine Learning},
  pages     = {4402--4412},
  year      = {2019},
  publisher = {PMLR}
}


@inproceedings{klicpera2019directional,
  title     = {Directional Message Passing for Molecular Graphs},
  author    = {Klicpera, Johannes and Gro{\ss}, Janek and G{\"u}nnemann, Stephan},
  booktitle = {International Conference on Learning Representations},
  year      = {2019}
}

@article{jing2020learning,
  title   = {Learning from Protein Structure with Geometric Vector Perceptrons},
  author  = {Jing, Bowen and Eismann, Stephan and Suriana, Patricia and Townshend, Raphael JL and Dror, Ron},
  journal = {arXiv preprint arXiv:2009.01411},
  year    = {2020}
}

@article{li2020graph,
  title     = {Graph neural network based coarse-grained mapping prediction},
  author    = {Li, Zhiheng and Wellawatte, Geemi P and Chakraborty, Maghesree and Gandhi, Heta A and Xu, Chenliang and White, Andrew D},
  journal   = {Chemical Science},
  volume    = {11},
  number    = {35},
  pages     = {9524--9531},
  year      = {2020},
  publisher = {Royal Society of Chemistry}
}

@article{yang2020predicting,
  title     = {Predicting Chemical Shifts with Graph Neural Networks},
  author    = {Yang, Ziyue and Chakraborty, Maghesree and White, Andrew D},
  journal   = {bioRxiv},
  year      = {2020},
  publisher = {Cold Spring Harbor Laboratory}
}

@article{maziarka2020molecule,
  title   = {Molecule Attention Transformer},
  author  = {Maziarka, {\L}ukasz and Danel, Tomasz and Mucha, S{\l}awomir and Rataj, Krzysztof and Tabor, Jacek and Jastrz{\k{e}}bski, Stanis{\l}aw},
  journal = {arXiv preprint arXiv:2002.08264},
  year    = {2020}
}

@article{miller2020relevance,
  title   = {Relevance of rotationally equivariant convolutions for predicting molecular properties},
  author  = {Miller, Benjamin Kurt and Geiger, Mario and Smidt, Tess E and No{\'e}, Frank},
  journal = {arXiv preprint arXiv:2008.08461},
  year    = {2020}
}


@article{wu2020stochastic,
  title   = {Stochastic Normalizing Flows},
  author  = {Wu, Hao and K{\"o}hler, Jonas and No{\'e}, Frank},
  journal = {arXiv preprint arXiv:2002.06707},
  year    = {2020}
}

@inproceedings{papamakarios2019sequential,
  title        = {Sequential neural likelihood: Fast likelihood-free inference with autoregressive flows},
  author       = {Papamakarios, George and Sterratt, David and Murray, Iain},
  booktitle    = {The 22nd International Conference on Artificial Intelligence and Statistics},
  pages        = {837--848},
  year         = {2019},
  organization = {PMLR}
}

@article{papamakarios2019normalizing,
  title   = {Normalizing flows for probabilistic modeling and inference},
  author  = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
  journal = {arXiv preprint arXiv:1912.02762},
  year    = {2019}
}

@inproceedings{zaheer2017deep,
  title     = {Deep sets},
  author    = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Russ R and Smola, Alexander J},
  booktitle = {Advances in neural information processing systems},
  pages     = {3391--3401},
  year      = {2017}
}

@inproceedings{kondor2018generalization,
  title     = {On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups},
  author    = {Kondor, Risi and Trivedi, Shubhendu},
  booktitle = {International Conference on Machine Learning},
  pages     = {2747--2755},
  year      = {2018}
}


@article{cohen2019general,
  title   = {A general theory of equivariant cnns on homogeneous spaces},
  author  = {Cohen, Taco S and Geiger, Mario and Weiler, Maurice},
  journal = {Advances in neural information processing systems},
  volume  = {32},
  pages   = {9145--9156},
  year    = {2019}
}


@article{winter2021auto,
  title   = {Auto-Encoding Molecular Conformations},
  author  = {Winter, Robin and No{\'e}, Frank and Clevert, Djork-Arn{\'e}},
  journal = {arXiv preprint arXiv:2101.01618},
  year    = {2021}
}

@article{finzi2020generalizing,
  title   = {Generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data},
  author  = {Finzi, Marc and Stanton, Samuel and Izmailov, Pavel and Wilson, Andrew Gordon},
  journal = {arXiv preprint arXiv:2002.12880},
  year    = {2020}
}

@article{romero2020attentive,
  title   = {Attentive Group Equivariant Convolutional Networks},
  author  = {Romero, David W and Bekkers, Erik J and Tomczak, Jakub M and Hoogendoorn, Mark},
  journal = {arXiv},
  pages   = {arXiv--2002},
  year    = {2020}
}

@inproceedings{cohen2016group,
  title     = {Group equivariant convolutional networks},
  author    = {Cohen, Taco and Welling, Max},
  booktitle = {International conference on machine learning},
  pages     = {2990--2999},
  year      = {2016}
}

@article{wang2020equivariant,
  title   = {Equivariant Maps for Hierarchical Structures},
  author  = {Wang, Renhao and Albooyeh, Marjan and Ravanbakhsh, Siamak},
  journal = {arXiv preprint arXiv:2006.03627},
  year    = {2020}
}

@article{batzner2021se3equivariant,
  title   = {SE(3)-Equivariant Graph Neural Networks for Data-Efficient and Accurate Interatomic Potentials},
  author  = {Simon Batzner and Tess E. Smidt and Lixin Sun and Jonathan P. Mailoa and Mordechai Kornbluth and Nicola Molinari and Boris Kozinsky},
  year    = {2021},
  journal = {arXiv preprint arXiv:2101.03164}
}

@article{klicpera2020directional,
  title   = {Directional message passing for molecular graphs},
  author  = {Klicpera, Johannes and Gro{\ss}, Janek and G{\"u}nnemann, Stephan},
  journal = {arXiv preprint arXiv:2003.03123},
  year    = {2020}
}

@book{serre1977linear,
  title     = {Linear representations of finite groups},
  author    = {Serre, Jean-Pierre},
  volume    = {42},
  year      = {1977},
  publisher = {Springer}
}

@book{zee2016,
  title     = {Group theory in a nutshell for physicists},
  author    = {Zee, Anthony},
  publisher = {Princeton University Press},
  year      = {2016}
}

@article{musil2021physicsinspired,
  title   = {Physics-inspired structural representations for molecules and materials},
  author  = {Felix Musil and Andrea Grisafi and Albert P. Bartók and Christoph Ortner and Gábor Csányi and Michele Ceriotti},
  journal = {arXiv preprint arXiv:2101.04673},
  year    = {2021}
}


@article{chew2020fast,
  title     = {Fast predictions of liquid-phase acid-catalyzed reaction rates using molecular dynamics simulations and convolutional neural networks},
  author    = {Chew, Alex K and Jiang, Shengli and Zhang, Weiqi and Zavala, Victor M and Van Lehn, Reid C},
  journal   = {Chemical Science},
  volume    = {11},
  number    = {46},
  pages     = {12464--12476},
  year      = {2020},
  publisher = {Royal Society of Chemistry}
}

@article{lang2020wigner,
  title   = {A Wigner-Eckart Theorem for Group Equivariant Convolution Kernels},
  author  = {Lang, Leon and Weiler, Maurice},
  journal = {arXiv preprint arXiv:2010.10952},
  year    = {2020}
}


@article{kondor2018clebsch,
  title   = {Clebsch-gordan nets: a fully fourier space spherical convolutional neural network},
  author  = {Kondor, Risi and Lin, Zhen and Trivedi, Shubhendu},
  journal = {arXiv preprint arXiv:1806.09231},
  year    = {2018}
}

@inproceedings{hoogeboom2021argmax,
  title     = {Argmax Flows: Learning Categorical Distributions with Normalizing Flows},
  author    = {Emiel Hoogeboom and Didrik Nielsen and Priyank Jaini and Patrick Forr{\'e} and Max Welling},
  booktitle = {Third Symposium on Advances in Approximate Bayesian Inference},
  year      = {2021},
  url       = {https://openreview.net/forum?id=fdsXhAy5Cp}
}

@article{Xie2018Crystal,
  title     = {Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties},
  author    = {Xie, Tian and Grossman, Jeffrey C.},
  journal   = {Phys. Rev. Lett.},
  volume    = {120},
  issue     = {14},
  pages     = {145301},
  numpages  = {6},
  year      = {2018},
  month     = {Apr},
  publisher = {American Physical Society},
  doi       = {10.1103/PhysRevLett.120.145301},
  url       = {https://link.aps.org/doi/10.1103/PhysRevLett.120.145301}
}
